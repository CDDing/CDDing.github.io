---
title: GPU Architecture (GPU 아키텍처) — 한글 정리
description: Georgia Tech CS8803 Module 4 — GPU 마이크로아키텍처, 멀티스레딩, 뱅크 충돌, GPU 파이프라인, 전역 메모리 코얼레싱
---

> **원문:** [CS8803 OMSCS — GPU Hardware and Software Notes (Module 4)](https://lowyx.com/posts/gt-gpu-notes/#module-4-gpu-architecture)

## 학습 목표

- GPU 마이크로아키텍처를 설명한다
- 기본적인 GPU 아키텍처 용어를 이해한다

**필수 자료:** [General-Purpose Graphics Processor Architectures, Chapter 3](https://galileo-gatech.primo.exlibrisgroup.com/discovery/fulldisplay?context=L&context=L&vid=01GALI_GIT:GT&vid=01GALI_GIT:GT&docid=alma9916162981502950&tab=default_tab&lang=en)

---

## Lesson 1: 멀티스레드 아키텍처

### GPU 복습

GPU의 기본 구조를 복습한다.

- GPU에는 수많은 코어가 있다.
- 각 코어는 멀티스레딩을 지원하여 워프(또는 웨이브프론트)를 실행한다.
- 각 코어에는 공유 메모리와 하드웨어 캐시가 있다.

### 멀티스레딩

5단계 파이프라인과 4개 명령어가 있는 GPU를 가정하자.

- **이상적 시나리오**: 각 명령어가 파이프라인을 한 단계씩 순차 진행한다.
- **순차(in-order) 프로세서**: 명령어 1이 캐시 미스를 일으키면, 의존 관계가 없는 명령어 2도 명령어 1이 완료될 때까지 대기해야 한다.
- **비순차(out-of-order) 프로세서**: 명령어 2가 명령어 1에 의존하지 않으면 먼저 실행을 시작할 수 있다. 명령어 1의 메모리 응답이 돌아온 후 명령어 4를 실행한다.
- **멀티스레딩**: 이전 명령어의 캐시 미스 여부와 무관하게 **다른 스레드의 명령어로 전환**한다. 서로 다른 스레드이므로 모두 독립적이다. 4개 스레드에서 각각 1개씩 명령어를 실행하며, 4개 메모리 요청을 동시에 생성할 수 있다.

### 멀티스레딩의 이점

GPU는 멀티스레딩을 활용하여 다수의 메모리 요청을 동시에 생성한다. 정지된 명령어를 기다리는 대신 다른 스레드의 명령어를 실행하여 병렬 실행과 더 많은 메모리 요청을 가능하게 한다.

- 멀티스레딩의 핵심 이점은 **프로세서 정지 시간(stall time)을 은닉**하는 것이다. 정지의 원인:
  - 캐시 미스
  - 분기 명령어
  - 긴 레이턴시 ALU 명령어
- GPU는 멀티스레딩으로 긴 레이턴시 문제를 완화한다.
  - 반면 CPU는 비순차 실행, 캐시 시스템, 명령어 수준 병렬성(ILP)으로 레이턴시를 해결한다.
- 메모리 레이턴시가 길수록 은닉에 필요한 **스레드 수도 증가**한다.

### 멀티스레딩을 위한 프론트엔드 확장

프론트엔드에는 여러 개의 프로그램 카운터(PC) 값이 존재한다. 각 워프에 PC 레지스터 1개가 필요하므로, 4개 워프를 지원하려면 PC 레지스터 4개가 필요하다. 레지스터 세트도 4벌이다.

GPU에서 컨텍스트 전환이란, 여러 PC 레지스터와 레지스터 파일 사이에서 **포인터를 전환**하는 것에 불과하다.

### CPU 컨텍스트 전환

CPU는 다른 방식으로 컨텍스트를 전환한다.

1. 스레드 실행 중에는 명령어 파이프라인, PC, 레지스터가 해당 스레드 전용이다.
2. T2에서 T3으로 전환 시, T2의 내용을 **메모리에 저장**하고 T3의 내용을 **메모리에서 로드**한다.
3. 완료 후 원래 스레드 컨텍스트를 실행한다.

CPU의 컨텍스트 전환은 레지스터 내용을 메모리에 저장·복원해야 하므로 **상당한 성능 오버헤드**를 유발한다.

### 멀티스레딩의 하드웨어 지원

- **프론트엔드에 여러 PC가 필요하다**
  - 워프 내 모든 스레드가 동일한 PC를 공유하므로, 워프당 PC 1개
- **대용량 레지스터 파일이 필요하다**
  - 각 스레드에 K개의 아키텍처 레지스터가 필요
  - 총 레지스터 파일 크기 = K × 스레드 수
  - K는 애플리케이션마다 다르다
- **점유율 계산과의 관계**
  - SM당 Y개 스레드, Z개 레지스터를 실행할 수 있다고 하자
  - Y는 PC 레지스터 수와 관련된다. PC 레지스터가 5개이면 최대 5 × 32 = 160개 스레드를 지원한다.
  - Z는 K와 관련된다.

### 점유율 계산 예제 재방문

SM이 256개 스레드를 실행할 수 있고, 64 × 1024개 레지스터와 32KB 공유 메모리를 보유한다고 가정하자(워프당 32개 스레드).

- **필요한 PC 수**: 256 ÷ 32 = **8개**
- **프로그램이 10개 명령어를 가지면, SM이 명령어를 페치해야 하는 횟수**: 10 × 8 = **80회**

---

## Lesson 2: 뱅크 충돌(Bank Conflict)

### CUDA 블록/스레드/워프

GPU에서는 하나의 멀티프로세서에서 여러 CUDA 블록이 실행되며, 각 블록에는 여러 스레드가 있다. 스레드 그룹은 워프로 실행된다. **레지스터는 스레드별로 존재**한다.

각 명령어가 소스 피연산자 2개를 읽고 1개를 쓴다고 가정하고, 실행 폭이 8이면: 한 번에 8 × 3(읽기 2 + 쓰기 1) = **24개 값**을 공급해야 한다.

### 포트(Port) vs 뱅크(Bank)

**포트**는 데이터 접근을 위한 하드웨어 인터페이스이다. 각 스레드가 읽기 2개, 쓰기 1개 포트를 필요로 하고 실행 폭이 4이면, 총 읽기 포트 8개, 쓰기 포트 4개가 된다. 포트는 물리적 배선이 필요하므로 상당한 공간을 차지한다.

**뱅크**는 레지스터 파일의 파티션 또는 그룹이다. 여러 뱅크에 동시 접근이 가능하므로, 모든 읽기·쓰기 포트를 갖출 필요가 없다. 더 적은 수의 포트를 가진 여러 뱅크를 사용하면 된다. **포트가 많을수록 배선과 자원 사용이 증가**하므로 뱅크를 사용하는 것이 중요하다.

### 뱅크 충돌

한 워프 내의 여러 스레드가 **동일한 뱅크에 동시 접근**하면 뱅크 충돌이 발생한다.

- **시나리오 1**: T1, T2, T3, T4에서 R1을 읽는 경우 — 각 스레드의 레지스터가 서로 다른 뱅크에 있으면 충돌 없이 동시 읽기가 가능하다.
- **시나리오 2**: T1에서 R1, R2, R3, R4를 읽는 경우 — 모두 같은 뱅크에 위치하므로, 8포트 버전은 문제 없지만, 4뱅크 버전은 한 번에 2개만 읽을 수 있어 **여러 사이클이 소요**된다.

### 스레드당 가변 레지스터 수

CUDA 프로그래밍에서는 스레드당 레지스터 수가 다를 수 있어 뱅크 충돌의 원인이 된다.

`R3 = R1 + R2` 연산을 가정하자.

- **Case 1** (스레드당 레지스터 4개): 각 스레드의 레지스터가 서로 다른 뱅크에 위치 → 뱅크 충돌 없음
- **Case 2** (스레드당 레지스터 2개): T1과 T2가 같은 뱅크에 위치 → R1, R2를 읽을 때 **뱅크 충돌 발생**

GPU는 워프 단위로 실행하므로, 여러 스레드가 동일한 레지스터를 동시에 읽는 상황이 생긴다.

### 레지스터 뱅크 충돌 해결

**컴파일 타임 최적화**가 첫 번째 해결책이다. 레지스터 ID는 정적(static) 시점에 알 수 있으므로, 컴파일러가 코드 레이아웃을 최적화할 수 있다.

**참고 — 정적(Static) vs 동적(Dynamic)**:

- **정적**: 코드 실행 전에 결정. 프로그램 입력에 의존하지 않는 속성. 정적 분석 = 컴파일 타임 분석.
- **동적**: 프로그램 입력에 의존하는 속성.

```asm
LOOP: ADD R1, R1, #1
      BREQ R1, 10, LOOP
```

이 루프가 10회 반복되면:
- 정적 명령어 수 = **2** (코드에 보이는 수)
- 동적 명령어 수 = 2 × 10 = **20**

컴파일 타임 분석으로 명령어 순서를 변경하여 뱅크 충돌을 제거할 수 있지만, **모든 뱅크 충돌을 회피할 수는 없다**.

### GPU 파이프라인의 실제 구조

실제 GPU 파이프라인은 5단계보다 더 복잡하다.

1. 레지스터 파일 접근이 1사이클 이상 걸릴 수 있다(뱅크 충돌, 또는 읽기 포트가 1개뿐인 경우).
2. 읽은 값은 **버퍼**에 저장된다.
3. **스코어보드(scoreboard)**가 명령어를 선택한다.

### 스코어보딩(Scoreboarding)

- CPU에서는 비순차 실행을 위해 동적 명령어 스케줄링에 사용된다.
- GPU에서는 워프 내 **모든 소스 피연산자가 준비되었는지 확인**하고, 여러 워프 중 어떤 워프를 실행 유닛에 보낼지 선택한다.
- 가능한 정책: 가장 오래된 워프 우선(oldest first) 등.

### 레지스터 값 읽기 흐름

1. 레지스터 파일 읽기에 수 사이클이 소요될 수 있다.
2. 준비된 레지스터 값은 버퍼에 저장된다.
3. 값이 저장될 때마다 준비 비트(ready bit)가 설정된다.
4. 모든 소스 피연산자의 준비 비트가 설정되면, 스코어보드가 해당 워프를 선택하여 실행 유닛으로 보낸다.

### 공유 메모리의 뱅크 충돌

뱅크 충돌은 공유 메모리에서도 발생한다. 공유 메모리는 온칩 저장소(스크래치패드 메모리)이며, 높은 메모리 대역폭을 제공하기 위해 뱅크로 구성된다.

```c
__shared__ float sharedInput[index1];
index1 = threadIdx.x * 4;
```

4개 뱅크를 가정하면: T1은 주소 4, T2는 주소 8, T3은 주소 12를 접근한다. 이 주소들이 모두 **같은 뱅크에 매핑**되므로 뱅크 충돌이 발생한다. 해결 방법은 소프트웨어 구조를 변경하는 것이다.

---

## Lesson 3: GPU 아키텍처 파이프라인

### GPU 파이프라인 동작

GPU 파이프라인에는 각 워프의 PC 값이 존재한다. 예를 들어 4개 워프가 있는 경우:

| 워프 | 블록 | 스레드 | PC |
|------|------|--------|----|
| 워프 1 | 블록 1 | 스레드 1-4 | 0x8000 |
| 워프 2 | 블록 1 | 스레드 5-8 | 0x8000 |
| 워프 3 | 블록 2 | 스레드 1-4 | 0x8000 |
| 워프 4 | 블록 2 | 스레드 5-8 | 0x8000 |

### 특수 레지스터

명령어 캐시(I-cache)에는 특수 레지스터를 사용하는 명령어가 있다:

- **`tid.x`** — 블록 내 스레드 ID를 저장하는 특수 레지스터
- **`ctaid.x`** — 그리드 내 블록 ID를 저장하는 특수 레지스터

### 파이프라인 실행 예시 (1): 워프 1

1. 프론트엔드가 PC 0x8000에서 명령어 `ADD R1, R1, 1`을 페치한다. 워프 전체에 대해 **명령어 1개만** 페치한다.
2. 디코드 단계에서 즉시값 1이 스코어보드의 모든 소스 2 버퍼에 브로드캐스트된다.
3. 레지스터 파일 접근 단계에서 T1~T4의 R1 값을 읽어 스코어보드에 저장한다.
4. 모든 소스 피연산자가 준비되면 워프가 선택되어 실행 단계로 보내진다.
5. 덧셈 결과가 쓰기 단계(write-back)에서 레지스터 파일에 기록된다.

### 파이프라인 실행 예시 (2): 워프 2

워프 2(블록 1, T5~T8)도 동일한 흐름으로 진행된다. T5~T8의 레지스터 값이 모두 동일하더라도 하드웨어는 워프 내 **모든 스레드에 대해 동일한 작업을 수행**한다.

### 파이프라인 실행 예시 (3): `ctaid.x`

워프 4가 PC 0x800A에서 `MOV R2, ctaid.x`를 페치하면, 워프 4의 블록 ID가 2이므로 `ctaid.x` 값도 2이다. 이 값이 스코어보드에 저장된 후 쓰기 단계에서 R2에 기록된다.

### 파이프라인 실행 예시 (4): `tid.x`

워프 4가 PC 0x8008에서 `tid.x`를 사용하는 명령어를 페치하면, T5~T8이므로 `tid.x` 값은 5, 6, 7, 8이 된다. 각 값이 스코어보드에 저장된 후 쓰기 단계에서 R1에 기록된다.

### 마스크 비트(Mask Bit)

4개 스레드를 모두 실행할 필요가 없는 경우가 있다. GPU는 어떤 스레드(레인)가 활성 상태인지를 **마스크 비트**로 저장한다. 하나의 ALU 실행 경로를 **레인(lane)**이라 한다.

- **활성 스레드**: 실제 연산을 수행한다.
- **비활성 스레드**: 어떤 작업도 수행하지 않는다.

예를 들어:
- 워프 1의 마스크 비트가 `1111`이면 → 4개 스레드 모두 실행
- 워프 2의 마스크 비트가 `1110`이면 → 처음 3개 레인(스레드)만 실행

---

## Lesson 4: 전역 메모리 코얼레싱(Global Memory Coalescing)

### 전역 메모리 접근

GPU 아키텍처에서 하나의 메모리 명령어는 **다수의 메모리 요청**을 생성할 수 있다. 워프 크기가 32이면 한 워프에서 최대 32개 요청이 발생한다.

대역폭 계산 예시:
- SM 32개, 각 SM에서 워프 1개 실행 → 32 × 32 = **1,024개 요청/사이클**
- 각 요청이 64바이트 → 사이클당 64KB
- GPU 클럭 1GHz 가정 → 필요한 메모리 대역폭: **64TB/s**

### 참고 — DRAM vs SRAM

| | SRAM | DRAM |
|---|---|---|
| 구성 | 6개 트랜지스터/비트 | 1개 트랜지스터/비트 |
| 용도 | 캐시 | 메인 메모리 |
| 특징 | 빠르지만 면적 큼 | 대용량이지만 핀 통신이 제한 요인 |

**HBM(High Bandwidth Memory)**은 이 문제를 해결한다:
1. DRAM을 적층하여 훨씬 높은 밀도를 제공한다.
2. 실리콘 인터포저로 GPU와 메모리를 연결하여 오프칩 통신을 회피한다.
3. GPU와 DRAM 간 모든 통신이 **동일 패키지 내**에서 이루어지므로 대역폭이 크게 증가한다.

### 메모리 코얼레싱

메모리가 높은 대역폭을 제공하더라도, 메모리 요청을 줄이는 것은 성능에 핵심적이다. GPU 캐시는 매우 작아서 메모리 대역폭을 쉽게 포화시킬 수 있기 때문이다.

**코얼레싱된(coalesced) 접근:**

```
Ld.global R1 → R1의 값이 워프 내에서 연속적 (0, 4, 8, 12, ...)
→ 모든 메모리 요청을 하나로 결합 가능 (예: 주소 0~63)
```

**비코얼레싱된(uncoalesced) 접근:**

```
Ld.global R2 → R2의 값이 128 간격으로 흩어져 있음
→ 각 메모리 요청을 개별적으로 전송해야 함
```

**코얼레싱 메모리**는 여러 메모리 요청을 하나의(또는 더 효율적인) 메모리 요청으로 결합한다.

- 연속적인 메모리 요청을 코얼레싱할 수 있다.
- 코얼레싱은 총 메모리 요청 수를 줄인다.
- GPU 소프트웨어 최적화의 **핵심 기법** 중 하나이다.

---

## 이 챕터에서 기억할 것

1. **멀티스레딩**은 GPU의 핵심 레이턴시 은닉 기법이다 — 정지된 스레드 대신 다른 스레드를 실행하여 파이프라인을 채운다.
2. **GPU vs CPU 컨텍스트 전환** — GPU는 포인터만 전환(비용 0), CPU는 레지스터를 메모리에 저장·복원(비용 큼).
3. **뱅크 충돌** — 여러 스레드가 같은 뱅크에 동시 접근하면 발생. 레지스터 파일과 공유 메모리 모두에서 발생한다.
4. **스코어보드** — 워프의 모든 소스 피연산자가 준비되었는지 확인하고 실행할 워프를 선택한다.
5. **마스크 비트** — 워프 내 활성/비활성 레인을 제어하여 불필요한 연산을 방지한다.
6. **메모리 코얼레싱** — 연속 메모리 접근을 결합하여 요청 수를 줄인다. 비코얼레싱 접근은 성능을 크게 저하시킨다.

> 이 문서는 Georgia Tech CS8803 GPU Hardware and Software — Module 4: GPU Architecture를 한글로 요약한 것입니다.
> 세부 사항은 [원본 강의 노트](https://lowyx.com/posts/gt-gpu-notes/#module-4-gpu-architecture)를 참조한다.
