---
title: Introduction of GPU (GPU 소개) — 한글 정리
description: Georgia Tech CS8803 Module 1 — GPU 기초, 병렬 프로세서 패러다임, GPU 아키텍처 개요, GPU 발전사
---

> **원문:** [CS8803 OMSCS — GPU Hardware and Software Notes (Module 1)](https://lowyx.com/posts/gt-gpu-notes/#module-1-introduction-of-gpu)

## 학습 목표

- GPU의 기본 배경을 설명한다
- 데이터 병렬 아키텍처의 기본 개념을 이해한다

**필수 자료:** [CUDA Programming Guide, Section 1-2, 4](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html) / [Performance Analysis and Tuning for GPGPU (Chapter 1)](https://galileo-gatech.primo.exlibrisgroup.com/discovery/fulldisplay?context=L&context=L&vid=01GALI_GIT:GT&vid=01GALI_GIT&docid=cdi_proquest_ebookcentral_EBC1092425&tab=default_tab&lang=en)

**선택 자료:** [Patterns for Parallel Programming (Chapter 2)](https://galileo-gatech.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_askewsholts_vlebooks_9780321630582&context=PC&vid=01GALI_GIT:GT&lang=en&adaptor=Primo%20Central)

---

## Lesson 1: GPU란 무엇인가

### GPU vs CPU

GPU가 왜 오늘날 중요한가? GPU는 처음에 3D 그래픽으로 주목받았지만, 이후 강력한 병렬 프로세서로 발전하였다. 오늘날 GPU는 ML 가속기 및 고성능 컴퓨팅과 자주 연관되며 그 다재다능함을 보여 준다.

CPU와 GPU의 핵심 차이는 대상 애플리케이션에 있다.

- **CPU**: 단일 스레드 애플리케이션에 맞추어져 최대 속도를 목표로 한다. 정확한 예외 처리(precise exception)를 우선시하며, 이는 프로그램 정확성과 디버깅에 중요하다.
- **GPU**: 병렬 처리에 특화되어 수많은 스레드를 동시에 처리한다. 정확한 예외 처리를 중시하지 않으며, OS 및 I/O 연산을 위한 전용 하드웨어를 활용한다. CPU가 호스트, GPU가 가속기로 동작하는 구조가 자연스럽게 형성된다.

### GPU ISA

ISA(Instruction Set Architecture)는 명령어 집합 아키텍처를 의미한다.

- **CPU**: 공개(open) ISA를 사용하여 하드웨어 플랫폼 간 소프트웨어 호환성을 보장한다.
- **GPU**: 가속기 모드로 동작하며, 드라이버가 하나의 ISA에서 특정 하드웨어용 ISA로 코드를 변환한다. PTX는 공개 가상 ISA로 도입되었다.

| | CPU | GPU |
|---|---|---|
| 대상 애플리케이션 | 지연 시간(latency)에 민감 | 처리량(throughput)에 민감 |
| 정확한 예외 처리 | 지원 | 미지원 |
| 역할 | 호스트 | 가속기 |
| ISA | 공개 | 공개/비공개 |
| 프로그래밍 모델 | SISD/SIMD | SPMD |

### SIMD vs SPMD

- **SISD** — Single Instruction, Single Data
- **SIMD** — Single Instruction, Multiple Data: 같은 명령어를 동시에 서로 다른 데이터에 적용한다. 이미지 처리, 벡터 연산 등 데이터 병렬 작업에 적합하다. 일관된 구조의 데이터가 필요하며, 분기/조건 로직에서 록스텝(lockstep) 실행으로 인한 제약이 있다.
- **SPMD** — Single Program, Multiple Data: 같은 프로그램을 각자의 방식으로 서로 다른 데이터에 적용한다. SIMD보다 유연하며 분기와 조건 로직을 처리할 수 있다. 복잡한 워크플로와 분산 컴퓨팅에 주로 사용된다. 다만 스레드 관리와 통신 오버헤드가 발생할 수 있다.

GPU의 프로그래밍 모델은 SPMD 모델로, 병렬 처리를 강조한다.

---

## Lesson 2: 현대 프로세서 패러다임

### CPU 파이프라인 기초

CPU 설계의 기초는 다음 단계로 구성된다:

1. **Fetch (인출)** — I-cache에서 명령어를 인출한다.
2. **Decode (디코드)** — 명령어를 해독한다. x86의 경우 하나의 명령어가 여러 micro-uop을 생성한다.
3. **Register Read (레지스터 읽기)** — 디코드 후 레지스터 파일에 접근한다.
4. **Schedule (스케줄)** — 실행할 명령어를 선택한다.
   - In-order 프로세서: 프로그램 순서대로 선택한다.
   - Out-of-order 프로세서: 준비된 명령어를 순서 무관하게 선택하여 더 많은 명령어를 병렬 실행한다.
5. **Execute (실행)** — 실제 연산 수행 또는 메모리 접근한다.
6. **Write-back (쓰기)** — 결과를 기록한다.

**슈퍼스칼라(Superscalar) 프로세서**는 하나 이상의 명령어를 동시에 인출·디코드·실행하여 CPU 성능을 향상시킨다.

### 명령어 수준 병렬성 (ILP)

슈퍼스칼라 프로세서는 명령어 수준 병렬성(ILP, Instruction Level Parallelism)을 높인다. ILP는 CPU 성능의 핵심이며, 프로세서가 독립적인 명령어를 찾아 효율을 향상시킨다. 슈퍼스칼라에서 IPC(Instructions Per Cycle)는 1보다 크다.

- **독립 명령어**: 서로의 결과에 의존하지 않으면 동시 실행이 가능하다.
- **의존 명령어**: 의존성이 있으면 순차 실행해야 한다.

Out-of-order 프로세서는 독립적인 명령어를 더 많이 찾아내어 ILP를 향상시킨다. ILP 향상은 CPU 설계의 주요 초점 중 하나이다.

### CPU 성능 향상 방법

1. **깊은 파이프라인** — 주파수를 높이지만, 더 정확한 분기 예측이 필요하다.
2. **큰 캐시** — 캐시 미스를 줄여 메모리 접근 시간을 크게 단축한다.

### 멀티스레딩

멀티스레딩은 여러 스레드를 활성화하여 CPU 성능을 높인다. 다른 스레드로 전환하여 준비된 명령어를 더 많이 검사할 수 있다. 멀티스레딩은 고성능 GPU의 핵심 요소이며, 비교적 적은 하드웨어 자원으로 구현 가능하다.

### 멀티프로세서

전체 자원을 늘려 많은 프로세서를 보유하는 방법이다. CPU와 GPU 모두에서 널리 사용된다.

---

## Lesson 3: 병렬 프로그램 작성법

### Amdahl의 법칙

병렬 프로그래밍의 기본 개념인 Amdahl의 법칙이다. 성능 향상(Speedup)은 다음과 같이 계산된다:

```
Speedup = 1 / (P/N + S)

P: 병렬화 가능 비율
S: 직렬 구간
N: 프로세서 수
```

병렬성이 충분하고 직렬 구간이 최소이면, 프로세서 수에 따라 성능이 거의 선형으로 확장된다. 그러나 직렬 구간이 커지면 확장성이 급격히 저하된다. **직렬 비율이 10%만 되어도 병렬화의 이점이 크게 제한된다.**

### 태스크 분해 vs 데이터 분해

배열 덧셈과 최소/최대값 찾기를 예로 들어 보자.

**태스크 분해(Task Decomposition):**
- 한 코어는 덧셈을 수행하고, 다른 코어는 최소/최대 연산을 수행한다.
- 배열 A는 두 코어 모두에 전송되어야 한다.

**데이터 분해(Data Decomposition):**
- 데이터를 두 코어로 분할한다.
- 합계와 최소/최대 모두에 대해 리덕션(reduction) 연산이 필요하다.

### Flynn의 분류법

| 분류 | 의미 |
|------|------|
| SISD | Single Instruction, Single Data |
| SIMD/SIMT | Single Instruction, Multiple Data / Thread |
| MISD | Multiple Instruction, Single Data (실질적으로 드물다) |
| MIMD | Multiple Instruction, Multiple Data |

- **CPU**: SISD, SIMD, MIMD가 될 수 있다. 벡터 처리 유닛으로 SIMD를 사용한다.
- **GPU**: 일반적으로 SIMT이다. 많은 ALU(산술 논리 장치) 유닛을 갖는다.
- SIMD와 SIMT의 차이는 이후 모듈에서 논의한다.

### SPMD 프로그래밍

GPU의 일반적인 프로그래밍 패턴이다.

- 모든 코어(스레드)가 같은 프로그램을 실행하되 서로 다른 데이터에 대해 동작한다.
- 데이터 분해가 SPMD의 전형적인 프로그래밍 패턴이다.
- **GPU 프로그래밍은 SIMT 하드웨어를 활용하는 SPMD 프로그래밍 스타일을 사용한다.**

CUDA 예제:

```c
vector_sum() {
    index;           // 스레드 ID로 구분
    sum += A[index]; // 각 스레드가 자신의 인덱스에 해당하는 요소를 더한다
}
```

모든 코어(스레드)가 같은 `vector_sum()`을 실행하며, 스레드 ID가 각 스레드의 작업을 구분한다.

---

## Lesson 4: GPU 아키텍처 소개

### GPU 아키텍처 개요

- 각 코어는 여러 스레드를 실행할 수 있다.
- CPU 코어에 해당하는 것을 NVIDIA에서는 **스트리밍 멀티프로세서(SM, Streaming Multiprocessor)** 라 한다.
- **스트림 프로세서(SP)** 는 GPU의 ALU 유닛으로, SIMT 레인 또는 코어라고도 한다.
- **본 강좌에서 코어 ≠ 스트림 프로세서이다.** CPU 코어와 GPU 코어의 혼동을 줄이기 위해 SIMT 레인을 코어라 부르지 않는다.

하나의 SM 내부에는 명령어 캐시, 디코더, 공유 메모리, 여러 스트림 프로세서가 포함된다.

### GPU 파이프라인

1. **Fetch** — 각 작업 항목을 인출하며, 멀티스레드 아키텍처를 위해 여러 레지스터를 사용한다.
2. **스케줄러** — 라운드 로빈 또는 캐시 미스·분기 예측을 고려하는 탐욕적(greedy) 스케줄러가 있다.
3. **Decode** — 인출된 명령어를 처리하고 레지스터 값을 읽는다.
4. **스코어보딩** — 준비된 워프를 선택한다.
5. **Execute** — 선택된 워프가 실행 유닛에서 실행된다.
6. **Write-back** — 결과를 기록한다.

### 워프(Warp) / 웨이브프론트(Wave-front)

본 강좌에서 워프와 웨이브프론트는 동의어로 사용된다.

여러 스레드가 모여 **워프(warp)** 또는 **웨이브프론트(wave-front)** 를 형성하며, 이것이 실행의 기본 단위이다. 워프당 하나의 명령어가 인출되고, 해당 워프의 모든 스레드가 동시에 실행된다.

- **워프 크기**: 마이크로 아키텍처에서 매우 중요한 개념이다. 오랫동안 **32 스레드**로 유지되어 왔으나 미래에 변경될 수 있다.
- 프로그래머가 커널에 스레드 수를 지정하면, 스레드는 워프 단위로 그룹화된다.
- 주어진 명령어의 소스 피연산자가 준비되면 전체 워프가 실행된다.

**예시**: 프로그래머가 12개 스레드를 지정하고 워프 크기가 4인 경우, 3개의 워프가 구성되며 각 워프의 4개 스레드가 함께 실행된다.

---

## Lesson 5: GPU 아키텍처의 발전사

### 전통적인 3D 그래픽스 파이프라인

GPU 발전의 주요 단계:

1. **전통적인 파이프라인 GPU** — 별도의 버텍스 처리 유닛과 픽셀 처리 유닛
2. **프로그래머블 GPU** — 버텍스/픽셀 셰이더를 위한 프로그래머블 유닛 도입
3. **통합 셰이더 → GPGPU** — 버텍스/픽셀 셰이더가 CUDA 프로그래머블 코어로 발전 (Tesla 아키텍처)
4. **현대 GPU** — ML 가속기 컴포넌트(텐서 코어 등)와 프로그래머블 기능 추가

초기 GPU의 주 역할은 입력된 3D 프리미티브를 기하학 처리 등 여러 단계를 거쳐 2D 프리미티브로 변환하고, 이를 화면의 픽셀로 렌더링하는 것이었다. 고정 기능 셰이더가 점차 프로그래머블하게 되면서 **통합 셰이더 아키텍처**(Tesla 아키텍처)가 등장하였다. 이 혁신으로 GPU는 그래픽과 범용 컴퓨팅을 모두 처리할 수 있게 되었다.

GPGPU라는 용어는 GPU를 범용 컴퓨팅에 사용하는 것을 구분하기 위해 도입되었으나, 오늘날에는 이 구분이 불필요해졌다.

### 프로그래머블 GPU 아키텍처의 발전

- **캐시 계층 구조**(L1, L2 등) 도입
- **FP32 → FP64** 확장으로 HPC 애플리케이션 지원
- **원자적(atomic) 연산**과 빠른 정수 연산 통합
- **HBM(High Bandwidth Memory)** 활용 — GPU 칩과 메모리의 직접 연결로 전례 없는 전송 속도 제공
- **더 작은 부동소수점 포맷(FP16)** 지원으로 ML 연산 병렬성 향상
- **텐서 코어** 채택으로 ML 애플리케이션 가속
- **트랜스포머 코어** 통합으로 트랜스포머 ML 워크로드 지원

### NVIDIA H100

NVIDIA GPU 아키텍처 H100(2023)의 주요 특징:

- 다양한 정밀도 지원: FP32, FP64, FP16, INT8, FP8
- 텐서 코어 (이전 세대 계승), ML 코어, GPU 코어가 현대 ML 애플리케이션의 요구를 충족
- 새로운 **트랜스포머 엔진** 도입
- 대용량 레지스터 파일과 **텐서 메모리 가속기(TMA)** 개념
- SM 수와 FP 유닛 수의 지속적 증가
- **NVIDIA NVLink** 스위치 시스템으로 다중 GPU 연결

---

## 이 챕터에서 기억할 것

1. **GPU는 처리량 중심 아키텍처**이다 — CPU는 지연 시간, GPU는 처리량에 민감한 애플리케이션을 대상으로 한다.
2. **SPMD 프로그래밍 모델**이 GPU의 핵심이다 — 같은 프로그램을 서로 다른 데이터에 적용하며, SIMT 하드웨어 위에서 실행된다.
3. **Amdahl의 법칙** — 직렬 구간이 10%만 되어도 병렬화의 이점이 크게 제한된다.
4. **워프(warp)** 는 GPU 실행의 기본 단위이며, 현재 크기는 32 스레드이다.
5. **GPU 아키텍처는 지속적으로 진화**한다 — 고정 기능 셰이더 → 프로그래머블 셰이더 → GPGPU → ML 가속기(텐서 코어, 트랜스포머 엔진).

> 이 문서는 Georgia Tech CS8803 GPU Hardware and Software — Module 1: Introduction of GPU를 한글로 요약한 것입니다.
> 세부 사항은 [원본 강의 노트](https://lowyx.com/posts/gt-gpu-notes/#module-1-introduction-of-gpu)를 참조한다.
