---
title: "GPU ì•„í‚¤í…ì²˜ í•™ìŠµ ë¡œê·¸"
sidebar:
  label: "GPU ì•„í‚¤í…ì²˜"
---

## GPU ë‚´ë¶€ êµ¬ì¡°

> **Q.** í–‰ë ¬ê³±ì— íš¨ìœ¨ì ì¸ ì•„í‚¤í…ì²˜ì–ì•„. ë°˜ë©´ì— ê·¸ë˜í”½ìŠ¤ ì»´í“¨íŒ… ì½”ì–´ëŠ” ë˜ìŠ¤í„°í™”ë¼ë˜ì§€ í´ë¦¬í•‘ ì´ëŸ° ê±°ì— íŠ¹í™”ë˜ë„ë¡ ë§Œë“  ì•„í‚¤í…ì²˜ë¼ëŠ” ê±° ë§ë‚˜?

ë°˜ì€ ë§ê³  ë°˜ì€ ì¢€ ì •ë¦¬ê°€ í•„ìš”í•´. GPU ì•ˆì—ëŠ” **ë‘ ì¢…ë¥˜**ê°€ ì„ì—¬ìˆê±°ë“ :

| ìœ ë‹›               | ì„±ê²©                               | ì˜ˆì‹œ                               |
| ---------------- | -------------------------------- | -------------------------------- |
| **ê³ ì • í•¨ìˆ˜ ìœ ë‹›**     | íŠ¹ì • ë‹¨ê³„ì— íŠ¹í™”ëœ ì „ìš© í•˜ë“œì›¨ì–´. í”„ë¡œê·¸ë˜ë° ë¶ˆê°€.    | ë˜ìŠ¤í„°ë¼ì´ì €, í´ë¦¬í•‘, ROP, í…ìŠ¤ì²˜ ìƒ˜í”ŒëŸ¬        |
| **ì…°ì´ë” ì½”ì–´ (ALU)** | **ë²”ìš© ì—°ì‚°ê¸°**. ë¶€ë™ì†Œìˆ˜ì  ì—°ì‚°ì„ ëŒ€ëŸ‰ ë³‘ë ¬ë¡œ ì‹¤í–‰. | ë²„í…ìŠ¤ ì…°ì´ë”, ì»´í“¨íŠ¸ ì…°ì´ë”, CUDA ì „ë¶€ ì—¬ê¸°ì„œ ì‹¤í–‰ |

ì…°ì´ë” ì½”ì–´ëŠ” "ê·¸ë˜í”½ìŠ¤ ì „ìš©"ì´ ì•„ë‹ˆì•¼. ë²”ìš© ë³‘ë ¬ ì—°ì‚°ê¸°ì´ê¸° ë•Œë¬¸ì— GPU ì»´í“¨íŒ…ì´ ê°€ëŠ¥í•œ ê±°ì•¼.

```
GPU
â”œâ”€ ì…°ì´ë” ì½”ì–´: ë²”ìš© ë³‘ë ¬ ì—°ì‚°ê¸° (ê·¸ë˜í”½ìŠ¤ + ì»´í“¨íŠ¸ ê²¸ìš©)
â”œâ”€ ê³ ì • í•¨ìˆ˜ ìœ ë‹›: ë˜ìŠ¤í„°ë¼ì´ì €, ROP ë“± (ê·¸ë˜í”½ìŠ¤ ì „ìš©)
â”œâ”€ Tensor Core: í–‰ë ¬ê³± íŠ¹í™” (NVIDIA GPU ì•ˆì— ì¡´ì¬)
â””â”€ ë¹„ë””ì˜¤ ì—”ì§„: ì½”ë± ì „ìš©
```

---

## NPU vs GPU vs Tensor Core

> **Q.** NPU ê°™ì€ ê°œë… ì´í•´ê°€ ë‚˜í•œí…Œ í•„ìš”í•œê°€? ì•ˆë‹¤ë©´ ì–´ë””ê¹Œì§€ ì•Œì•„ì•¼ í•´?

GPU í”„ë¡œê·¸ë˜ë¨¸ ì§€ë§ì´ë©´ ê¹Šê²Œ ì•Œ í•„ìš”ëŠ” ì—†ê³ , **ê°œë…ê³¼ ê²½ê³„ë§Œ** ì•Œë©´ ë¼.

| | GPU ì…°ì´ë” ì½”ì–´ | Tensor Core | NPU |
|--|----------------|-------------|-----|
| ìœ„ì¹˜ | GPU ì•ˆ | GPU ì•ˆ | GPU ë°– (ë³„ë„ ì¹©) |
| ì„±ê²© | ë²”ìš© ë³‘ë ¬ ì—°ì‚° | í–‰ë ¬ê³± íŠ¹í™” | í–‰ë ¬ê³± íŠ¹í™” (ì¶”ë¡ ) |
| ì¥ì  | ìœ ì—°ì„± | GPU ë‚´ë¶€ë¼ ë°ì´í„° êµí™˜ ë¹ ë¦„ | ì „ë ¥ íš¨ìœ¨ì´ ì¢‹ìŒ |
| ìš©ë„ | ê·¸ë˜í”½ìŠ¤, ì»´í“¨íŠ¸ ì „ë°˜ | í•™ìŠµ/ì¶”ë¡ , í˜¼í•© ì •ë°€ë„ ì—°ì‚° | ëª¨ë°”ì¼ ì˜¨ë””ë°”ì´ìŠ¤ ì¶”ë¡  |

NVIDIA ë°©í–¥ì´ë©´ **Tensor Core**ê°€ ë” ê´€ë ¨ ìˆìŒ â€” GPU ì•ˆì— ìˆì–´ì„œ ì…°ì´ë” ì½”ì–´ì™€ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆê³ , CUDAì™€ ì§ì ‘ ì—°ê³„ë¨.

---

## ì–¸ë¦¬ì–¼ ì—”ì§„ ë“œë¡œìš°ì½œ íë¦„

> **Q.** ì§„ì§œ ë”´ ì§ˆë¬¸ì¸ë° ì–¸ë¦¬ì–¼ ì—”ì§„ì€ ë“œë¡œìš°ì½œì´ ì–´ë–»ê²Œ ì¼ì–´ë‚˜? í° í‹€ë§Œ.

ì•± ë ˆë²¨ì—ì„œëŠ” ë“œë¡œìš°ì½œì„ ì§ì ‘ ì•ˆ í•´. ì•¡í„°ë¥¼ ì›”ë“œì— ë°°ì¹˜í•˜ê³  ë¨¸í‹°ë¦¬ì–¼ ë¶™ì´ë©´ ì—”ì§„ì´ ì•Œì•„ì„œ ì²˜ë¦¬.

```
1. ì”¬ ìˆœíšŒ â†’ ë Œë”ë§ ê°€ëŠ¥í•œ ì•¡í„° ìˆ˜ì§‘
2. ì»¬ë§ â†’ Frustum Culling + Occlusion Culling
3. ì†ŒíŒ… & ë°°ì¹­ â†’ ê°™ì€ ë¨¸í‹°ë¦¬ì–¼ ë¬¶ê¸°, Instancing, Nanite ë¶„ê¸°
4. ë Œë”ë§ íŒ¨ìŠ¤ ì‹¤í–‰ â†’ Depth Prepass â†’ Base Pass â†’ Lighting â†’ Post Process
5. ê° íŒ¨ìŠ¤ ì•ˆì—ì„œ ì‹¤ì œ ë“œë¡œìš°ì½œ ë°œìƒ
   â””â”€ RHI ë ˆì´ì–´ê°€ Vulkanì´ë©´ vkCmdDraw, DX12ë©´ DrawInstancedë¡œ ë³€í™˜
```

í•µì‹¬ì€ **RHI(Rendering Hardware Interface) ë ˆì´ì–´**. ê·¸ë˜í”½ìŠ¤ APIë¥¼ ì¶”ìƒí™”í•´ì„œ ê°™ì€ ê²Œì„ ì½”ë“œê°€ Vulkan, DX12, Metal ìœ„ì—ì„œ ë™ì‘.

NaniteëŠ” ì „í†µì ì¸ ë“œë¡œìš°ì½œ ëŒ€ì‹  **ì»´í“¨íŠ¸ ì…°ì´ë”ë¡œ ì†Œí”„íŠ¸ì›¨ì–´ ë˜ìŠ¤í„°ë¼ì´ì§•**ì„ í•´ì„œ ë“œë¡œìš°ì½œ ìì²´ë¥¼ ìš°íšŒí•˜ëŠ” êµ¬ì¡°.

---

## Precise Exception â€” CPU vs GPU

> **Q.** CPUì—ì„œ "ì •í™•í•œ ì˜ˆì™¸ ì²˜ë¦¬(precise exception)ë¥¼ ìš°ì„ ì‹œí•œë‹¤"ëŠ” ê²Œ ë¬´ìŠ¨ ëœ»ì´ì•¼? GPUëŠ” ì™œ ì´ë¥¼ ìš°ì„ ì‹œí•˜ì§€ ì•Šì•„?

**Precise exception**ì´ë€ ì˜ˆì™¸ ë°œìƒ ì‹œ í”„ë¡œì„¸ì„œ ìƒíƒœê°€ **í”„ë¡œê·¸ë¨ ìˆœì„œëŒ€ë¡œ ì •í™•íˆ ë³´ì¡´**ëœ ê²ƒì„ ì˜ë¯¸í•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ì˜ˆì™¸ê°€ ë°œìƒí•œ ëª…ë ¹ì–´ ì´ì „ì˜ ëª¨ë“  ëª…ë ¹ì–´ëŠ” commit ì™„ë£Œ, ì´í›„ì˜ ëª…ë ¹ì–´ëŠ” ìƒíƒœë¥¼ ë³€ê²½í•˜ì§€ ì•Šì€ ìƒíƒœë¥¼ ë³´ì¥í•œë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì˜ˆì™¸ í•¸ë“¤ëŸ¬ê°€ [ì •í™•íˆ ê·¸ ì§€ì ì—ì„œ ì‹¤í–‰ì„ ì¬ê°œ](https://fiveable.me/advanced-computer-architecture/unit-3/exception-handling-pipelined-processors/study-guide/ulz8mSCscBUvbxNp)í•  ìˆ˜ ìˆë‹¤.

### CPU â€” Precise Exceptionì´ í•„ìˆ˜ì¸ ì´ìœ 

CPUëŠ” out-of-order ì‹¤í–‰ì„ í•˜ë©´ì„œë„ [Reorder Buffer(ROB)](https://en.wikipedia.org/wiki/Out-of-order_execution)ë¡œ í”„ë¡œê·¸ë¨ ìˆœì„œë¥¼ ì¶”ì í•˜ì—¬ precise exceptionì„ ë³´ì¥í•œë‹¤.

**Page Fault ì˜ˆì‹œ:**

```
ëª…ë ¹ì–´ 1: a = b + c       â† commit ì™„ë£Œ
ëª…ë ¹ì–´ 2: d = memory[X]   â† Page Fault ë°œìƒ (ë©”ëª¨ë¦¬ê°€ ë””ìŠ¤í¬ì— ìˆìŒ)
ëª…ë ¹ì–´ 3: e = f * g       â† ìƒíƒœ ë³€ê²½ ì—†ìŒ
```

OSê°€ í˜ì´ì§€ë¥¼ ë””ìŠ¤í¬ì—ì„œ ë¡œë“œí•œ ë’¤, **ëª…ë ¹ì–´ 2ë¶€í„° ì •í™•íˆ ì¬ê°œ**í•  ìˆ˜ ìˆë‹¤. ì´ ì™¸ì—ë„ 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸°, segfault, ë””ë²„ê±° ë¸Œë ˆì´í¬í¬ì¸íŠ¸ ë“±ì—ì„œ ì •í™•í•œ ìœ„ì¹˜ë¥¼ ì•Œ ìˆ˜ ìˆì–´ì•¼ í”„ë¡œê·¸ë¨ ì •í™•ì„±ê³¼ ë””ë²„ê¹…ì´ ê°€ëŠ¥í•˜ë‹¤.

### GPU â€” Imprecise Exceptionì„ ì„ íƒí•œ ì´ìœ 

GPUëŠ” precise exceptionì— í•„ìš”í•œ í•˜ë“œì›¨ì–´ ë¹„ìš©(ROB ë“±)ì„ **ALUë¥¼ ë” ë„£ëŠ” ë°** ì‚¬ìš©í•œë‹¤. íŠ¸ë ˆì´ë“œì˜¤í”„:

| | CPU | GPU |
|---|---|---|
| ì˜ˆì™¸ ì²˜ë¦¬ | **Precise** â€” ì •í™•í•œ ì§€ì ì—ì„œ ìƒíƒœ ë³´ì¡´Â·ì¬ê°œ | **Imprecise** â€” ëŒ€ëµì  ìœ„ì¹˜, ë¹„ë™ê¸° ë³´ê³  |
| ì´ìœ  | ë””ë²„ê¹…, OS ê°€ìƒ ë©”ëª¨ë¦¬, í”„ë¡œê·¸ë¨ ì •í™•ì„± | ì²˜ë¦¬ëŸ‰ ê·¹ëŒ€í™”, í•˜ë“œì›¨ì–´ ë¹„ìš© ì ˆê° |
| ë””ë²„ê¹… | ì •í™•í•œ ìœ„ì¹˜ ì¦‰ì‹œ í™•ì¸ | ë³„ë„ ë„êµ¬([cuda-memcheck](https://docs.nvidia.com/cuda/cuda-gdb/index.html), cuda-gdb) í•„ìš” |

GPUì—ì„œ ë©”ëª¨ë¦¬ í´íŠ¸ê°€ ë°œìƒí•˜ë©´, [í•´ë‹¹ í´íŠ¸ëŠ” CPUë¡œ ì „ë‹¬](https://dl.acm.org/doi/10.1145/3123939.3123950)ë˜ì–´ CPUê°€ ì²˜ë¦¬í•˜ë©° ê·¸ ë™ì•ˆ GPU íŒŒì´í”„ë¼ì¸ì˜ í•´ë‹¹ ìŠ¤ë ˆë“œëŠ” ì •ì§€ëœë‹¤. ìˆ˜ë§Œ ê°œ ìŠ¤ë ˆë“œ ê°ê°ì— precise exceptionì„ ë³´ì¥í•˜ëŠ” ê²ƒì€ í˜„ì‹¤ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥ì— ê°€ê¹Œìš°ë¯€ë¡œ, GPUëŠ” ì²˜ë¦¬ëŸ‰ì„ ìœ„í•´ ì´ë¥¼ í¬ê¸°í•œ ê²ƒì´ë‹¤.

> ğŸ“š **ì°¸ê³ **
> - [Exception Handling in Pipelined Processors â€” Fiveable](https://fiveable.me/advanced-computer-architecture/unit-3/exception-handling-pipelined-processors/study-guide/ulz8mSCscBUvbxNp) â€” precise vs imprecise exception ì •ì˜
> - [Efficient Exception Handling Support for GPUs â€” ACM MICRO'17](https://dl.acm.org/doi/10.1145/3123939.3123950) â€” GPU ì˜ˆì™¸ ì²˜ë¦¬ì˜ í•œê³„ì™€ í•´ê²° ë°©ì•ˆ
> - [CUDA-GDB Documentation â€” NVIDIA](https://docs.nvidia.com/cuda/cuda-gdb/index.html) â€” GPU ë””ë²„ê¹… ì‹œ imprecise exception ëŒ€ì‘
> - [Out-of-Order Execution â€” Wikipedia](https://en.wikipedia.org/wiki/Out-of-order_execution) â€” ROBì™€ precise exceptionì˜ ê´€ê³„

---

## ê°€ì†ê¸° ëª¨ë“œì™€ PTX

> **Q.** GPUì—ì„œ "ê°€ì†ê¸° ëª¨ë“œ"ëŠ” ë¬´ìŠ¨ ë§ì´ì•¼? PTXëŠ” ë­ì•¼?

### ê°€ì†ê¸° ëª¨ë“œ(Accelerator Mode)

GPUëŠ” **í˜¼ìì„œ ë…ë¦½ì ìœ¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ë‹¤**ëŠ” ì˜ë¯¸ì´ë‹¤. CPUê°€ í˜¸ìŠ¤íŠ¸(host), GPUê°€ ì¥ì¹˜(device/accelerator)ë¡œ ë™ì‘í•˜ëŠ” êµ¬ì¡°:

- **CPU**: OS ì‹¤í–‰, ë©”ëª¨ë¦¬ í• ë‹¹, I/O ê´€ë¦¬, í”„ë¡œê·¸ë¨ ì‹œì‘ â€” ëª¨ë“  ê²ƒì„ ìŠ¤ìŠ¤ë¡œ ìˆ˜í–‰
- **GPU**: CPUê°€ "ì´ ë°ì´í„°ë¡œ ì´ ì»¤ë„ ì‹¤í–‰í•´"ë¼ê³  **ì§€ì‹œí•´ì•¼ë§Œ ë™ì‘**

[CUDAì—ì„œëŠ”](https://docs.nvidia.com/cuda/cuda-programming-guide/01-introduction/cuda-platform.html) CPUê°€ ë©”ëª¨ë¦¬ë¥¼ í• ë‹¹í•˜ê³ (`cudaMalloc`), ë°ì´í„°ë¥¼ ì „ì†¡í•˜ê³ (`cudaMemcpy`), ì»¤ë„ ì‹¤í–‰ì„ ì§€ì‹œ(`kernel<<<...>>>`)í•˜ëŠ” ì „ ê³¼ì •ì„ ì£¼ë„í•œë‹¤. GPUì—ëŠ” OSë„, íŒŒì¼ ì‹œìŠ¤í…œë„, I/O ì²˜ë¦¬ ì „ìš© í•˜ë“œì›¨ì–´ë„ ì—†ë‹¤.

### PTX (Parallel Thread Execution)

CPUì˜ ISA(ì˜ˆ: x86)ëŠ” ê³µê°œë˜ì–´ ìˆê³  ì„¸ëŒ€ê°€ ë°”ë€Œì–´ë„ í•˜ìœ„ í˜¸í™˜ëœë‹¤. ë°˜ë©´ GPUëŠ” ì„¸ëŒ€ë§ˆë‹¤ **ì‹¤ì œ í•˜ë“œì›¨ì–´ ISA(SASS)ê°€ ë‹¤ë¥´ë‹¤** (sm_80, sm_90 ë“±). ë§¤ë²ˆ ì¬ì»´íŒŒì¼í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ NVIDIAê°€ ë„ì…í•œ **ê°€ìƒ(virtual) ISA**ê°€ [PTX](https://docs.nvidia.com/cuda/parallel-thread-execution/)ì´ë‹¤.

```
CUDA C/C++  â†’  PTX (ê°€ìƒ ISA, í•˜ë“œì›¨ì–´ ë…ë¦½)  â†’  SASS (ì‹¤ì œ ëª…ë ¹ì–´, GPU ì„¸ëŒ€ë³„)
              ì»´íŒŒì¼ íƒ€ì„(nvcc)                  ì„¤ì¹˜/ì‹¤í–‰ ì‹œ(ë“œë¼ì´ë²„ JIT)
```

PTXì˜ ì„¤ê³„ ëª©í‘œ:
1. **ì—¬ëŸ¬ GPU ì„¸ëŒ€ì— ê±¸ì³ ì•ˆì •ì ì¸ ISA** ì œê³µ
2. ë„¤ì´í‹°ë¸Œ GPU ì„±ëŠ¥ì— ë¹„ê²¬ë˜ëŠ” ì„±ëŠ¥
3. C/C++ ì»´íŒŒì¼ëŸ¬ê°€ íƒ€ê²Ÿìœ¼ë¡œ ì‚¼ì„ ìˆ˜ ìˆëŠ” **ë¨¸ì‹  ë…ë¦½ ISA**

Java ë°”ì´íŠ¸ì½”ë“œê°€ JVM ìœ„ì—ì„œ í”Œë«í¼ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë“¯, PTXëŠ” GPU ë“œë¼ì´ë²„ ìœ„ì—ì„œ GPU ì„¸ëŒ€ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ëœë‹¤.

> ğŸ“š **ì°¸ê³ **
> - [PTX ISA 9.1 â€” NVIDIA Official Documentation](https://docs.nvidia.com/cuda/parallel-thread-execution/) â€” PTX ì •ì˜, ì„¤ê³„ ëª©í‘œ, ì»´íŒŒì¼ íŒŒì´í”„ë¼ì¸
> - [The CUDA Platform â€” CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-programming-guide/01-introduction/cuda-platform.html) â€” CUDA â†’ PTX â†’ cubin ì»´íŒŒì¼ íë¦„
> - [Introduction to GPU Architecture â€” ENCCS](https://enccs.github.io/openmp-gpu/gpu-architecture/) â€” CPU host / GPU device êµ¬ì¡°

---

## SM, SP, ì›Œí”„ì˜ ê´€ê³„

> **Q.** SMì´ ì—¬ëŸ¬ SPë¥¼ ë³´ìœ í•˜ê³ , SMì´ SPë¥¼ ìš´ìš©í•˜ëŠ” ë‹¨ìœ„ê°€ ì›Œí”„/ì›¨ì´ë¸Œí”„ë¡ íŠ¸ â€” ë§ë‚˜?

ë°©í–¥ì€ ë§ì§€ë§Œ í•œ ê°€ì§€ ë³´ì •ì´ í•„ìš”í•˜ë‹¤. ì›Œí”„ëŠ” **SP(í•˜ë“œì›¨ì–´)ì˜ ê·¸ë£¹ì´ ì•„ë‹ˆë¼ ìŠ¤ë ˆë“œ(ì†Œí”„íŠ¸ì›¨ì–´)ì˜ ê·¸ë£¹**ì´ë‹¤.

### ì •í™•í•œ ê³„ì¸µ êµ¬ì¡°

- **SM (Streaming Multiprocessor)**: SPë“¤ + ì›Œí”„ ìŠ¤ì¼€ì¤„ëŸ¬ + ë ˆì§€ìŠ¤í„° íŒŒì¼ + ê³µìœ  ë©”ëª¨ë¦¬ë¥¼ ë¬¶ì€ ì‹¤í–‰ ë‹¨ìœ„. CPU ì½”ì–´ì— ëŒ€ì‘.
- **SP (Stream Processor / CUDA Core)**: í•˜ë‚˜ì˜ ALU. í•œ ë²ˆì— í•˜ë‚˜ì˜ ìŠ¤ë ˆë“œ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ëŠ” í•˜ë“œì›¨ì–´.
- **ì›Œí”„ (Warp)**: [32ê°œ **ìŠ¤ë ˆë“œ**ì˜ ë¬¶ìŒ](https://docs.nvidia.com/cuda/cuda-programming-guide/01-introduction/programming-model.html). SMì˜ ì›Œí”„ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ê´€ë¦¬í•˜ëŠ” ìµœì†Œ ìŠ¤ì¼€ì¤„ë§ ë‹¨ìœ„.

í”„ë¡œê·¸ë˜ë¨¸ê°€ 1024ê°œ ìŠ¤ë ˆë“œë¥¼ ìš”ì²­í•˜ë©´ â†’ 32ê°œì”© ë¬¶ì–´ ì›Œí”„ 32ê°œ ìƒì„± â†’ ì›Œí”„ ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì¤€ë¹„ëœ ì›Œí”„ë¥¼ ê³¨ë¼ SPë“¤ì— ë§¤í•‘í•˜ì—¬ ì‹¤í–‰. SMì—ëŠ” SP ìˆ˜ë³´ë‹¤ ì›Œí”„ê°€ í›¨ì”¬ ë§ì´ ì¡´ì¬í•  ìˆ˜ ìˆìœ¼ë©°, ì›Œí”„ Aê°€ ë©”ëª¨ë¦¬ ëŒ€ê¸° ì¤‘ì´ë©´ ì¦‰ì‹œ ì›Œí”„ Bë¡œ ì „í™˜í•˜ì—¬ [ë ˆì´í„´ì‹œë¥¼ ìˆ¨ê¸´ë‹¤](https://modal.com/gpu-glossary/device-software/warp).

### ë²¤ë”ë³„ ìš©ì–´ ì°¨ì´

| ê°œë… | NVIDIA | AMD | Intel (Xe) |
|------|--------|-----|------------|
| ì‹¤í–‰ ë‹¨ìœ„ ë¬¶ìŒ | SM | CU (Compute Unit) | EU (Execution Unit) |
| ALU ìœ ë‹› | SP / CUDA Core | Stream Processor | ALU |
| ìŠ¤ë ˆë“œ ê·¸ë£¹ | Warp (32) | Wavefront (64, RDNAëŠ” 32ë„ ì§€ì›) | SIMD Thread (8~16) |
| ìŠ¤ë ˆë“œ ë¸”ë¡ | Thread Block | Work-group | Work-group |

ê°•ì˜ì—ì„œ "ì›Œí”„/ì›¨ì´ë¸Œí”„ë¡ íŠ¸ë¥¼ ë™ì˜ì–´ë¡œ ì‚¬ìš©í•œë‹¤"ê³  í•œ ì´ìœ ëŠ” ê°™ì€ ê°œë…ì˜ ë²¤ë”ë³„ ì´ë¦„ì´ê¸° ë•Œë¬¸ì´ë‹¤. OpenCL í‘œì¤€ì—ì„œëŠ” ë²¤ë” ì¤‘ë¦½ì ìœ¼ë¡œ **sub-group**ì´ë¼ ë¶€ë¥¸ë‹¤.

> ğŸ“š **ì°¸ê³ **
> - [CUDA Programming Guide â€” Programming Model](https://docs.nvidia.com/cuda/cuda-programming-guide/01-introduction/programming-model.html) â€” ìŠ¤ë ˆë“œ â†’ ì›Œí”„ â†’ ë¸”ë¡ â†’ SM ë§¤í•‘
> - [What is a Warp? â€” GPU Glossary (Modal)](https://modal.com/gpu-glossary/device-software/warp) â€” ì›Œí”„ ì •ì˜, SM-ì›Œí”„-ìŠ¤ë ˆë“œ ê³„ì¸µ êµ¬ì¡°
> - [Understanding Warp Scheduling â€” NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/understanding-warp-scheduling-on-a-streaming-multiprocessor/359568) â€” ì›Œí”„ ìŠ¤ì¼€ì¤„ë§ ë©”ì»¤ë‹ˆì¦˜
