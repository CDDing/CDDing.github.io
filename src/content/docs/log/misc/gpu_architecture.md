---
title: "GPU 아키텍처 학습 로그"
sidebar:
  label: "GPU 아키텍처"
---

## GPU 내부 구조

> **Q.** 행렬곱에 효율적인 아키텍처잖아. 반면에 그래픽스 컴퓨팅 코어는 래스터화라던지 클리핑 이런 거에 특화되도록 만든 아키텍처라는 거 맞나?

반은 맞고 반은 좀 정리가 필요해. GPU 안에는 **두 종류**가 섞여있거든:

| 유닛               | 성격                               | 예시                               |
| ---------------- | -------------------------------- | -------------------------------- |
| **고정 함수 유닛**     | 특정 단계에 특화된 전용 하드웨어. 프로그래밍 불가.    | 래스터라이저, 클리핑, ROP, 텍스처 샘플러        |
| **셰이더 코어 (ALU)** | **범용 연산기**. 부동소수점 연산을 대량 병렬로 실행. | 버텍스 셰이더, 컴퓨트 셰이더, CUDA 전부 여기서 실행 |

셰이더 코어는 "그래픽스 전용"이 아니야. 범용 병렬 연산기이기 때문에 GPU 컴퓨팅이 가능한 거야.

```
GPU
├─ 셰이더 코어: 범용 병렬 연산기 (그래픽스 + 컴퓨트 겸용)
├─ 고정 함수 유닛: 래스터라이저, ROP 등 (그래픽스 전용)
├─ Tensor Core: 행렬곱 특화 (NVIDIA GPU 안에 존재)
└─ 비디오 엔진: 코덱 전용
```

---

## NPU vs GPU vs Tensor Core

> **Q.** NPU 같은 개념 이해가 나한테 필요한가? 안다면 어디까지 알아야 해?

GPU 프로그래머 지망이면 깊게 알 필요는 없고, **개념과 경계만** 알면 돼.

| | GPU 셰이더 코어 | Tensor Core | NPU |
|--|----------------|-------------|-----|
| 위치 | GPU 안 | GPU 안 | GPU 밖 (별도 칩) |
| 성격 | 범용 병렬 연산 | 행렬곱 특화 | 행렬곱 특화 (추론) |
| 장점 | 유연성 | GPU 내부라 데이터 교환 빠름 | 전력 효율이 좋음 |
| 용도 | 그래픽스, 컴퓨트 전반 | 학습/추론, 혼합 정밀도 연산 | 모바일 온디바이스 추론 |

NVIDIA 방향이면 **Tensor Core**가 더 관련 있음 — GPU 안에 있어서 셰이더 코어와 데이터를 빠르게 주고받을 수 있고, CUDA와 직접 연계됨.

---

## 언리얼 엔진 드로우콜 흐름

> **Q.** 진짜 딴 질문인데 언리얼 엔진은 드로우콜이 어떻게 일어나? 큰 틀만.

앱 레벨에서는 드로우콜을 직접 안 해. 액터를 월드에 배치하고 머티리얼 붙이면 엔진이 알아서 처리.

```
1. 씬 순회 → 렌더링 가능한 액터 수집
2. 컬링 → Frustum Culling + Occlusion Culling
3. 소팅 & 배칭 → 같은 머티리얼 묶기, Instancing, Nanite 분기
4. 렌더링 패스 실행 → Depth Prepass → Base Pass → Lighting → Post Process
5. 각 패스 안에서 실제 드로우콜 발생
   └─ RHI 레이어가 Vulkan이면 vkCmdDraw, DX12면 DrawInstanced로 변환
```

핵심은 **RHI(Rendering Hardware Interface) 레이어**. 그래픽스 API를 추상화해서 같은 게임 코드가 Vulkan, DX12, Metal 위에서 동작.

Nanite는 전통적인 드로우콜 대신 **컴퓨트 셰이더로 소프트웨어 래스터라이징**을 해서 드로우콜 자체를 우회하는 구조.
